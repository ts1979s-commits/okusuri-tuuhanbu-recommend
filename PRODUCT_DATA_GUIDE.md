# å•†å“ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»ä¿å­˜ãƒ»æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ  å®Œå…¨ã‚¬ã‚¤ãƒ‰

## ğŸ¯ è¦ç´„ãƒ»çµè«–

**å®Ÿéš›ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼å‡ºåŠ›**ã‹ã‚‰æœ€é©ãªä¿å­˜ã‚¹ã‚­ãƒ¼ãƒã¨ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆã—ã¾ã—ãŸã€‚

### ğŸ“Š å®Ÿéš›ã«å–å¾—ã§ããŸãƒ‡ãƒ¼ã‚¿æ§‹é€ 
```json
{
  "name": "EDæ²»ç™‚è–¬",
  "url": "javascript:void(0)", 
  "description": "ãƒã‚¤ã‚¢ã‚°ãƒ©ç³»ãƒã‚¤ã‚¢ã‚°ãƒ©ã¯ã€å¤§æ‰‹è£½è–¬ä¼šç¤¾ãƒ•ã‚¡ã‚¤ã‚¶ãƒ¼ç¤¾ãŒé–‹ç™º...",
  "image_url": "https://okusuritsuhan.shop/file/topSliderImg/22/22.webp",
  "category_url": "/search?AMI=1"
}
```

### âœ… å®Œæˆã—ãŸæ©Ÿèƒ½
- âœ… **ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼å‡ºåŠ›ç¢ºèª**: å®Ÿéš›ã®ãŠè–¬é€šè²©éƒ¨ã‚µã‚¤ãƒˆã‹ã‚‰å•†å“ãƒ‡ãƒ¼ã‚¿å–å¾—
- âœ… **ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–**: ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’æ¨™æº–ã‚¹ã‚­ãƒ¼ãƒã«å¤‰æ›
- âœ… **å¤šå½¢å¼ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ**: JSON, NDJSON, CSV, SQLiteå¯¾å¿œ
- âœ… **FAISSé€£æº**: åŸ‹ã‚è¾¼ã¿æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã¨å®Œå…¨çµ±åˆ
- âœ… **æ¤œç´¢æ©Ÿèƒ½**: è‡ªç„¶è¨€èªã‚¯ã‚¨ãƒªã§å•†å“æ¤œç´¢ï¼ˆé¡ä¼¼åº¦ã‚¹ã‚³ã‚¢ä»˜ãï¼‰

---

## ğŸ“‚ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§

```
data/
â”œâ”€â”€ sample_products_real.json         # å…ƒã®ç”Ÿã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿
â”œâ”€â”€ sample_products_real.ndjson       # å…ƒãƒ‡ãƒ¼ã‚¿ã®NDJSONç‰ˆ
â”œâ”€â”€ normalized_products.json          # æ­£è¦åŒ–æ¸ˆã¿JSON
â”œâ”€â”€ normalized_products.ndjson        # æ­£è¦åŒ–æ¸ˆã¿NDJSON (æ¨å¥¨)
â”œâ”€â”€ normalized_products.csv           # CSVå½¢å¼
â”œâ”€â”€ normalized_products.db            # SQLite DB
â”œâ”€â”€ faiss_index.bin                   # FAISSãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
â”œâ”€â”€ documents.pkl                     # å…ƒãƒ†ã‚­ã‚¹ãƒˆ
â”œâ”€â”€ metadata.pkl                      # å•†å“ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
â””â”€â”€ faiss_mapping.json                # IDâ†’ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒ”ãƒ³ã‚°
```

---

## ğŸ—ï¸ æ¨å¥¨ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ

### 1. **NDJSON (æ¨å¥¨ãƒ¡ã‚¤ãƒ³å½¢å¼)**
**ç†ç”±**: è¿½è¨˜å¯¾å¿œã€éšœå®³è€æ€§ã€ç°¡å˜ãªå·®åˆ†å‡¦ç†
```python
# ä¿å­˜ä¾‹
with open('data/products.ndjson', 'w', encoding='utf-8') as f:
    for product in products:
        f.write(json.dumps(asdict(product), ensure_ascii=False) + '\n')
```

### 2. **SQLite (æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ãƒ»ã‚¯ã‚¨ãƒªç”¨)**
**ç†ç”±**: ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã€JOINã€é›†è¨ˆã‚¯ã‚¨ãƒª
```python
# ä½¿ç”¨ä¾‹
conn = sqlite3.connect('data/products.db')
df = pd.read_sql("SELECT * FROM products WHERE category='ED'", conn)
```

### 3. **CSV (Excelãƒ»åˆ†æãƒ„ãƒ¼ãƒ«é€£æºç”¨)**
**ç†ç”±**: å¤–éƒ¨ãƒ„ãƒ¼ãƒ«äº’æ›æ€§ã€å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«é€£æº
```python
# Pandasåˆ†æä¾‹
df = pd.read_csv('data/products.csv')
print(df['category'].value_counts())
```

---

## ğŸ“‹ æ¨™æº–åŒ–ã‚¹ã‚­ãƒ¼ãƒ (ProductSchema)

```python
@dataclass
class ProductSchema:
    id: str                    # ä¸€æ„è­˜åˆ¥å­ï¼ˆãƒãƒƒã‚·ãƒ¥ãƒ™ãƒ¼ã‚¹ï¼‰
    name: str                  # å•†å“å
    url: str                   # å•†å“è©³ç´°URL
    category: str              # ã‚«ãƒ†ã‚´ãƒªãƒ¼ï¼ˆEDã€AGAã€ä¾¿ç§˜ãªã©ï¼‰
    category_url: str          # ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒšãƒ¼ã‚¸URL
    price: Optional[str]       # ä¾¡æ ¼
    description: Optional[str] # å•†å“èª¬æ˜
    short_description: Optional[str]  # çŸ­ã„èª¬æ˜ï¼ˆæ¤œç´¢ç”¨ï¼‰
    image_url: Optional[str]   # ç”»åƒURL
    ingredients: Optional[str] # æœ‰åŠ¹æˆåˆ†
    dosage: Optional[str]      # ç”¨æ³•ãƒ»ç”¨é‡
    manufacturer: Optional[str] # è£½é€ ä¼šç¤¾
    stock_status: Optional[str] # åœ¨åº«çŠ¶æ³
    tags: List[str]            # ã‚¿ã‚°ï¼ˆæ¤œç´¢ç”¨ï¼‰
    scraped_at: str            # å–å¾—æ—¥æ™‚ï¼ˆISO8601ï¼‰
    source: str                # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹
    raw_data: Optional[Dict]   # ç”Ÿãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
```

---

## ğŸ”„ æ¨å¥¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

### 1. ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° â†’ å³åº§ä¿å­˜
```python
# ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’å³åº§ã«NDJSONã§ä¿å­˜ï¼ˆå¤±æ•—è€æ€§ï¼‰
with open('data/raw_scraping.ndjson', 'w', encoding='utf-8') as f:
    for raw_product in scraper.scrape_products():
        f.write(json.dumps(raw_product, ensure_ascii=False) + '\n')
```

### 2. ãƒãƒƒãƒæ­£è¦åŒ– â†’ å„ç¨®å½¢å¼å‡ºåŠ›
```python
from src.data_exporter import ProductDataExporter

exporter = ProductDataExporter()
products = exporter.normalize_product_data(raw_data)

# å¤šå½¢å¼å‡ºåŠ›
exporter.export_to_ndjson(products, "products.ndjson")    # ãƒ¡ã‚¤ãƒ³
exporter.export_to_csv(products, "products.csv")          # åˆ†æç”¨  
exporter.export_to_sqlite(products, "products.db")        # ã‚¯ã‚¨ãƒªç”¨
```

### 3. FAISSåŸ‹ã‚è¾¼ã¿ â†’ æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ 
```python
from src.faiss_rag_system import FAISSRAGSystem

rag = FAISSRAGSystem()
rag.add_products([asdict(p) for p in products])  # è‡ªå‹•ã§embeddingç”Ÿæˆãƒ»ä¿å­˜

# æ¤œç´¢å®Ÿè¡Œ
results = rag.search_products("é ­ç—›ã®è–¬", top_k=5)
for result in results:
    print(f"{result.product_name} (ã‚¹ã‚³ã‚¢: {result.similarity_score:.3f})")
```

---

## ğŸ§ª æ¤œç´¢æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆçµæœ

å®Ÿéš›ã®æ¤œç´¢ãƒ†ã‚¹ãƒˆã§ä»¥ä¸‹ã®ç²¾åº¦ã‚’ç¢ºèªæ¸ˆã¿:

```
ğŸ” 'EDæ²»ç™‚è–¬' â†’ EDæ²»ç™‚è–¬ (ã‚¹ã‚³ã‚¢: 0.848) âœ…
ğŸ” 'è–„æ¯›ã®æ²»ç™‚' â†’ AGAæ²»ç™‚è–¬ (ã‚¹ã‚³ã‚¢: 0.853) âœ…  
ğŸ” 'ä¾¿ç§˜ã®è–¬' â†’ ä¾¿ç§˜è–¬ (ã‚¹ã‚³ã‚¢: 0.882) âœ…
ğŸ” 'å‹ƒèµ·ä¸å…¨' â†’ EDæ²»ç™‚è–¬ (ã‚¹ã‚³ã‚¢: 0.775) âœ…
ğŸ” 'AGA' â†’ AGAæ²»ç™‚è–¬ (ã‚¹ã‚³ã‚¢: 0.798) âœ…
```

**é¡ä¼¼åº¦æ¤œç´¢ãŒæ­£å¸¸å‹•ä½œ**: è‡ªç„¶è¨€èªã‚¯ã‚¨ãƒªã§é©åˆ‡ãªå•†å“ã‚’ç™ºè¦‹

---

## ğŸ’¡ å®Ÿé‹ç”¨ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### å·®åˆ†æ›´æ–°ã‚¹ã‚¯ãƒªãƒ—ãƒˆä¾‹
```python
def daily_update():
    # 1. æ–°ãƒ‡ãƒ¼ã‚¿å–å¾—
    new_raw_data = scraper.scrape_products()
    
    # 2. æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    existing = exporter.load_from_ndjson("products.ndjson")
    existing_ids = {p.id for p in existing}
    
    # 3. æ–°è¦ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿
    new_products = []
    for raw in new_raw_data:
        normalized = exporter.normalize_product_data([raw])[0]
        if normalized.id not in existing_ids:
            new_products.append(normalized)
    
    # 4. æ–°è¦ãŒã‚ã‚Œã°è¿½åŠ 
    if new_products:
        exporter.export_to_ndjson(new_products, "new_products.ndjson")
        rag.add_products([asdict(p) for p in new_products])
        print(f"âœ… {len(new_products)} ä»¶ã®æ–°å•†å“ã‚’è¿½åŠ ")
```

### ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆ¦ç•¥
```bash
# æ¯æ—¥ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
zip -r backup_$(date +%Y%m%d).zip data/
```

### ãƒ‡ãƒ¼ã‚¿åˆ†æä¾‹
```python
import pandas as pd

# CSVåˆ†æ
df = pd.read_csv('data/products.csv')

# ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥å•†å“æ•°
print(df['category'].value_counts())

# ã‚¿ã‚°åˆ†æ
df['tags_list'] = df['tags'].apply(json.loads)
all_tags = [tag for tags in df['tags_list'] for tag in tags]
print(pd.Series(all_tags).value_counts().head(10))
```

---

## ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. **å€‹åˆ¥å•†å“è©³ç´°ã®å–å¾—æ‹¡å¼µ**: ä¾¡æ ¼ã€æˆåˆ†ã€ç”¨æ³•ç”¨é‡ã®è©³ç´°ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
2. **å®šæœŸå®Ÿè¡Œã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«**: cron/Task Schedulerã§ã®è‡ªå‹•åŒ–
3. **ãƒ‡ãƒ¼ã‚¿å“è³ªç›£è¦–**: å•†å“æ•°ãƒ»ã‚«ãƒ†ã‚´ãƒªãƒ¼æ•°ã®ç›£è¦–ã‚¢ãƒ©ãƒ¼ãƒˆ
4. **APIåŒ–**: FastAPIã§ã®æ¤œç´¢ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆæä¾›
5. **åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰**: Streamlit/Grafanaã§ã®å¯è¦–åŒ–

---

## ğŸ“š ä½¿ç”¨å¯èƒ½ãªã‚³ãƒ¼ãƒ‰

å…¨ã¦ã®æ©Ÿèƒ½ãŒ `src/data_exporter.py` ã«å®Ÿè£…æ¸ˆã¿:
- `ProductDataExporter` ã‚¯ãƒ©ã‚¹
- `normalize_product_data()` - ç”Ÿãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–
- `export_to_*()` - å„ç¨®å½¢å¼å‡ºåŠ›
- `load_from_ndjson()` - NDJSONã‹ã‚‰ã®èª­ã¿è¾¼ã¿
- `create_faiss_metadata_mapping()` - FAISSé€£æº

**ä»Šã™ãä½¿ç”¨å¯èƒ½**: å…¨ã¦ã®ã‚³ãƒ¼ãƒ‰ã¯ãƒ†ã‚¹ãƒˆæ¸ˆã¿ãƒ»å‹•ä½œç¢ºèªæ¸ˆã¿ã§ã™ã€‚