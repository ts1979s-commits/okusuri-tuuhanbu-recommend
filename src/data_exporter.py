"""
å•†å“ãƒ‡ãƒ¼ã‚¿ã®æœ€é©åŒ–ã•ã‚ŒãŸã‚¹ã‚­ãƒ¼ãƒå®šç¾©ã¨ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½
å–å¾—ã—ãŸå®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«è¨­è¨ˆ
"""
import json
import csv
import sqlite3
import hashlib
from datetime import datetime
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, asdict
from pathlib import Path

@dataclass
class ProductSchema:
    """å•†å“ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–ã‚¹ã‚­ãƒ¼ãƒ"""
    id: str                    # ä¸€æ„è­˜åˆ¥å­ï¼ˆURL or ãƒãƒƒã‚·ãƒ¥ãƒ™ãƒ¼ã‚¹ï¼‰
    name: str                  # å•†å“å
    url: str                   # å•†å“è©³ç´°URL
    category: str              # ã‚«ãƒ†ã‚´ãƒªãƒ¼ï¼ˆEDæ²»ç™‚è–¬ã€AGAæ²»ç™‚è–¬ãªã©ï¼‰
    category_url: str          # ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒšãƒ¼ã‚¸URL
    price: Optional[str] = None              # ä¾¡æ ¼
    description: Optional[str] = None        # å•†å“èª¬æ˜
    short_description: Optional[str] = None  # çŸ­ã„èª¬æ˜ï¼ˆæ¤œç´¢ç”¨ï¼‰
    image_url: Optional[str] = None          # ç”»åƒURL
    ingredients: Optional[str] = None        # æœ‰åŠ¹æˆåˆ†
    dosage: Optional[str] = None             # ç”¨æ³•ãƒ»ç”¨é‡
    manufacturer: Optional[str] = None       # è£½é€ ä¼šç¤¾
    stock_status: Optional[str] = None       # åœ¨åº«çŠ¶æ³
    tags: List[str] = None                   # ã‚¿ã‚°ï¼ˆæ¤œç´¢ç”¨ï¼‰
    scraped_at: str = None                   # å–å¾—æ—¥æ™‚ï¼ˆISO8601ï¼‰
    source: str = "okusuritsuhan.shop"       # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹
    raw_data: Optional[Dict] = None          # ç”Ÿãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰

    def __post_init__(self):
        if self.tags is None:
            self.tags = []
        if self.scraped_at is None:
            self.scraped_at = datetime.utcnow().isoformat()

class ProductDataExporter:
    """å•†å“ãƒ‡ãƒ¼ã‚¿ã®å„ç¨®å½¢å¼ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½"""
    
    def __init__(self, data_dir: str = "data"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)
    
    def normalize_product_data(self, raw_products: List[Dict]) -> List[ProductSchema]:
        """ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’æ¨™æº–ã‚¹ã‚­ãƒ¼ãƒã«å¤‰æ›"""
        normalized = []
        
        for raw in raw_products:
            # IDã®ç”Ÿæˆï¼ˆURLã¾ãŸã¯åå‰ã®ãƒãƒƒã‚·ãƒ¥ãƒ™ãƒ¼ã‚¹ï¼‰
            id_source = raw.get('url', raw.get('name', ''))
            product_id = hashlib.md5(id_source.encode('utf-8')).hexdigest()[:12]
            
            # ã‚«ãƒ†ã‚´ãƒªãƒ¼åã®æŠ½å‡º
            category = raw.get('name', '').replace('æ²»ç™‚è–¬', '').replace('è–¬', '').strip()
            
            # èª¬æ˜æ–‡ã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
            description = raw.get('description', '')
            if description:
                # æ”¹è¡Œã¨ä½™åˆ†ãªç©ºç™½ã‚’æ•´ç†
                description = ' '.join(description.split())
                
            # çŸ­ã„èª¬æ˜ã®ç”Ÿæˆï¼ˆæœ€åˆã®100æ–‡å­—ï¼‰
            short_desc = description[:100] if description else None
            
            # ã‚¿ã‚°ã®ç”Ÿæˆï¼ˆã‚«ãƒ†ã‚´ãƒªãƒ¼ã¨èª¬æ˜ã‹ã‚‰ï¼‰
            tags = [category]
            if description:
                # ç°¡å˜ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
                keywords = ['æ²»ç™‚', 'åŠ¹æœ', 'æˆåˆ†', 'æœç”¨', 'ç—‡çŠ¶']
                for keyword in keywords:
                    if keyword in description:
                        tags.append(keyword)
            
            product = ProductSchema(
                id=product_id,
                name=raw.get('name', ''),
                url=raw.get('url', ''),
                category=category,
                category_url=raw.get('category_url', ''),
                description=description,
                short_description=short_desc,
                image_url=raw.get('image_url'),
                tags=list(set(tags)),  # é‡è¤‡é™¤å»
                raw_data=raw
            )
            
            normalized.append(product)
        
        return normalized
    
    def export_to_json(self, products: List[ProductSchema], filename: str = "products.json"):
        """JSONå½¢å¼ã§å‡ºåŠ›"""
        filepath = self.data_dir / filename
        
        products_dict = [asdict(product) for product in products]
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(products_dict, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ JSONå½¢å¼ã§ä¿å­˜: {filepath}")
        return filepath
    
    def export_to_ndjson(self, products: List[ProductSchema], filename: str = "products.ndjson"):
        """NDJSONï¼ˆè¡ŒæŒ‡å‘JSONï¼‰å½¢å¼ã§å‡ºåŠ›"""
        filepath = self.data_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            for product in products:
                f.write(json.dumps(asdict(product), ensure_ascii=False) + '\n')
        
        print(f"ğŸ’¾ NDJSONå½¢å¼ã§ä¿å­˜: {filepath}")
        return filepath
    
    def export_to_csv(self, products: List[ProductSchema], filename: str = "products.csv"):
        """CSVå½¢å¼ã§å‡ºåŠ›ï¼ˆãƒã‚¹ãƒˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯JSONæ–‡å­—åˆ—åŒ–ï¼‰"""
        filepath = self.data_dir / filename
        
        if not products:
            print("âš ï¸ ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹å•†å“ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return None
        
        # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã‚’å–å¾—
        fieldnames = list(asdict(products[0]).keys())
        
        with open(filepath, 'w', encoding='utf-8', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            
            for product in products:
                row = asdict(product)
                # ãƒªã‚¹ãƒˆã‚„è¾æ›¸ã¯JSONæ–‡å­—åˆ—ã«å¤‰æ›
                for key, value in row.items():
                    if isinstance(value, (list, dict)):
                        row[key] = json.dumps(value, ensure_ascii=False)
                
                writer.writerow(row)
        
        print(f"ğŸ’¾ CSVå½¢å¼ã§ä¿å­˜: {filepath}")
        return filepath
    
    def export_to_sqlite(self, products: List[ProductSchema], filename: str = "products.db"):
        """SQLiteå½¢å¼ã§å‡ºåŠ›"""
        filepath = self.data_dir / filename
        
        conn = sqlite3.connect(filepath)
        cursor = conn.cursor()
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS products (
            id TEXT PRIMARY KEY,
            name TEXT NOT NULL,
            url TEXT,
            category TEXT,
            category_url TEXT,
            price TEXT,
            description TEXT,
            short_description TEXT,
            image_url TEXT,
            ingredients TEXT,
            dosage TEXT,
            manufacturer TEXT,
            stock_status TEXT,
            tags TEXT,  -- JSONé…åˆ—ã¨ã—ã¦ä¿å­˜
            scraped_at TEXT,
            source TEXT,
            raw_data TEXT,  -- JSONæ–‡å­—åˆ—ã¨ã—ã¦ä¿å­˜
            created_at DATETIME DEFAULT CURRENT_TIMESTAMP
        )
        ''')
        
        # ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥
        for product in products:
            data = asdict(product)
            # JSONãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ–‡å­—åˆ—åŒ–
            data['tags'] = json.dumps(data['tags'], ensure_ascii=False)
            data['raw_data'] = json.dumps(data['raw_data'], ensure_ascii=False) if data['raw_data'] else None
            
            cursor.execute('''
            INSERT OR REPLACE INTO products 
            (id, name, url, category, category_url, price, description, short_description,
             image_url, ingredients, dosage, manufacturer, stock_status, tags, 
             scraped_at, source, raw_data)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                data['id'], data['name'], data['url'], data['category'], 
                data['category_url'], data['price'], data['description'], 
                data['short_description'], data['image_url'], data['ingredients'],
                data['dosage'], data['manufacturer'], data['stock_status'],
                data['tags'], data['scraped_at'], data['source'], data['raw_data']
            ))
        
        conn.commit()
        conn.close()
        
        print(f"ğŸ’¾ SQLiteå½¢å¼ã§ä¿å­˜: {filepath}")
        return filepath
    
    def load_from_ndjson(self, filename: str = "products.ndjson") -> List[ProductSchema]:
        """NDJSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        filepath = self.data_dir / filename
        
        if not filepath.exists():
            print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filepath}")
            return []
        
        products = []
        with open(filepath, 'r', encoding='utf-8') as f:
            for line in f:
                data = json.loads(line.strip())
                product = ProductSchema(**data)
                products.append(product)
        
        print(f"ğŸ“‚ NDJSONã‹ã‚‰ {len(products)} ä»¶ã®å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿: {filepath}")
        return products
    
    def create_faiss_metadata_mapping(self, products: List[ProductSchema]) -> Dict[int, Dict]:
        """FAISSã®åŸ‹ã‚è¾¼ã¿IDã¨å•†å“ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½œæˆ"""
        mapping = {}
        
        for i, product in enumerate(products):
            mapping[i] = {
                'product_id': product.id,
                'name': product.name,
                'category': product.category,
                'url': product.url,
                'short_description': product.short_description
            }
        
        # ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’JSONã§ä¿å­˜
        mapping_file = self.data_dir / "faiss_mapping.json"
        with open(mapping_file, 'w', encoding='utf-8') as f:
            json.dump(mapping, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ”— FAISSãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä¿å­˜: {mapping_file}")
        return mapping

def demo_export_pipeline():
    """å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ãŸã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã®ãƒ‡ãƒ¢"""
    print("ğŸ“Š å•†å“ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®ãƒ‡ãƒ¢")
    print("="*60)
    
    # å–å¾—æ¸ˆã¿ã®å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    try:
        with open('data/sample_products_real.json', 'r', encoding='utf-8') as f:
            raw_data = json.load(f)
    except FileNotFoundError:
        print("âŒ sample_products_real.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–
    exporter = ProductDataExporter()
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–
    print("ğŸ”„ ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’æ¨™æº–ã‚¹ã‚­ãƒ¼ãƒã«å¤‰æ›ä¸­...")
    normalized_products = exporter.normalize_product_data(raw_data)
    
    print(f"âœ… {len(normalized_products)} ä»¶ã®å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–")
    
    # å„å½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
    print("\nğŸ“¤ å„å½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­...")
    exporter.export_to_json(normalized_products, "normalized_products.json")
    exporter.export_to_ndjson(normalized_products, "normalized_products.ndjson")
    exporter.export_to_csv(normalized_products, "normalized_products.csv")
    exporter.export_to_sqlite(normalized_products, "normalized_products.db")
    
    # FAISSãƒãƒƒãƒ”ãƒ³ã‚°ä½œæˆ
    print("\nğŸ”— FAISSãƒãƒƒãƒ”ãƒ³ã‚°ä½œæˆä¸­...")
    mapping = exporter.create_faiss_metadata_mapping(normalized_products)
    
    # çµæœã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print(f"\nğŸ“‹ æ­£è¦åŒ–å¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«:")
    print("="*60)
    
    for i, product in enumerate(normalized_products):
        print(f"\nğŸ”¸ å•†å“ {i+1}:")
        print(f"  ID: {product.id}")
        print(f"  åå‰: {product.name}")
        print(f"  ã‚«ãƒ†ã‚´ãƒªãƒ¼: {product.category}")
        print(f"  URL: {product.url}")
        print(f"  èª¬æ˜: {product.short_description}")
        print(f"  ã‚¿ã‚°: {product.tags}")
        print(f"  å–å¾—æ—¥æ™‚: {product.scraped_at}")

if __name__ == "__main__":
    demo_export_pipeline()