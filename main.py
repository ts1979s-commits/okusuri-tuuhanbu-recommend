"""
ãŠè–¬é€šè²©éƒ¨å•†å“ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰LLMã‚¢ãƒ—ãƒª - æœ¬ç•ªé‹ç”¨ç‰ˆ
ãƒ•ã‚§ãƒ¼ã‚º1å®Ÿè£…: RAGãƒ™ãƒ¼ã‚¹ã®å•†å“æ¤œç´¢ãƒ»ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰ã‚·ã‚¹ãƒ†ãƒ 
"""
import sys
import os
import logging
from pathlib import Path
from datetime import datetime

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent
sys.path.append(str(project_root))

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/app.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ - æœ¬ç•ªé‹ç”¨ç‰ˆ"""
    print("ğŸ¥ ãŠè–¬é€šè²©éƒ¨å•†å“ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰LLMã‚¢ãƒ—ãƒª - æœ¬ç•ªé‹ç”¨ç‰ˆ")
    print("=" * 60)
    
    # åˆæœŸåŒ–ãƒã‚§ãƒƒã‚¯
    if not initialize_system():
        print("âŒ ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    while True:
        print("\n" + "="*60)
        print("ğŸ“‹ ãƒ¡ã‚¤ãƒ³ãƒ¡ãƒ‹ãƒ¥ãƒ¼")
        print("="*60)
        print("1. ğŸ•·ï¸  å•†å“ãƒ‡ãƒ¼ã‚¿åé›† (ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°)")
        print("2. ï¿½ ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ»ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
        print("3. ï¿½ğŸ” å•†å“æ¤œç´¢ãƒ»ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰ (CLI)")
        print("4. ğŸŒ Web UIèµ·å‹• (Streamlit)")
        print("5. ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª")
        print("6. ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—")
        print("7. ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»çµ±è¨ˆ")
        print("8. âš™ï¸  ã‚·ã‚¹ãƒ†ãƒ è¨­å®š")
        print("0. çµ‚äº†")
        
        choice = input("\nç•ªå·ã‚’å…¥åŠ›: ").strip()
        
        try:
            if choice == "1":
                run_data_collection()
            elif choice == "2":
                run_data_processing()
            elif choice == "3":
                run_cli_recommendation()
            elif choice == "4":
                run_web_ui()
            elif choice == "5":
                check_system_status()
            elif choice == "6":
                run_backup()
            elif choice == "7":
                run_data_analysis()
            elif choice == "8":
                show_system_settings()
            elif choice == "0":
                print("ğŸ”š ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã¾ã™")
                logger.info("ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çµ‚äº†")
                break
            else:
                print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™")
        except KeyboardInterrupt:
            print("\nâš ï¸ æ“ä½œãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ")
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            logger.error(f"ãƒ¡ãƒ‹ãƒ¥ãƒ¼å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")

def initialize_system():
    """ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
    try:
        # å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        directories = ['data', 'logs', 'backups', 'reports']
        for dir_name in directories:
            Path(dir_name).mkdir(exist_ok=True)
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        from config.settings import get_settings
        settings = get_settings()
        
        if not settings.OPENAI_API_KEY:
            print("âš ï¸ OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            print("   .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦API Keyã‚’è¨­å®šã—ã¦ãã ã•ã„")
            return False
        
        print("âœ… ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        logger.info("ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        return True
        
    except Exception as e:
        print(f"âŒ ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def run_data_collection():
    """å•†å“ãƒ‡ãƒ¼ã‚¿åé›†ï¼ˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼‰"""
    print("\nğŸ•·ï¸ å•†å“ãƒ‡ãƒ¼ã‚¿åé›†ã‚’é–‹å§‹...")
    logger.info("å•†å“ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹")
    
    try:
        from src.scraper import OkusuriScraper
        from src.data_exporter import ProductDataExporter
        import json
        
        scraper = OkusuriScraper()
        exporter = ProductDataExporter()
        
        print("ğŸ“¡ ãŠè–¬é€šè²©éƒ¨ã‚µã‚¤ãƒˆã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
        
        # å®Ÿéš›ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè¡Œï¼ˆãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
        print("âš ï¸ ç¾åœ¨ã¯ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™")
        
        # æ—¢å­˜ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        sample_file = Path("data/sample_products_real.json")
        if sample_file.exists():
            with open(sample_file, 'r', encoding='utf-8') as f:
                raw_data = json.load(f)
            
            # ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–
            normalized = exporter.normalize_product_data(raw_data)
            
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ•ã‚¡ã‚¤ãƒ«åã§ä¿å­˜
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # å„ç¨®å½¢å¼ã§ä¿å­˜
            exporter.export_to_ndjson(normalized, f"products_{timestamp}.ndjson")
            exporter.export_to_csv(normalized, f"products_{timestamp}.csv")
            exporter.export_to_sqlite(normalized, f"products_{timestamp}.db")
            
            # ãƒ¡ã‚¤ãƒ³ç”¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚æ›´æ–°
            exporter.export_to_ndjson(normalized, "products.ndjson")
            
            print(f"âœ… {len(normalized)} ä»¶ã®å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ãƒ»ä¿å­˜å®Œäº†")
            logger.info(f"å•†å“ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†: {len(normalized)} ä»¶")
            
        else:
            print("âŒ ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿åé›†ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"ãƒ‡ãƒ¼ã‚¿åé›†ã‚¨ãƒ©ãƒ¼: {e}")

def run_data_processing():
    """ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ»ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
    print("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ»ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ¡ãƒ‹ãƒ¥ãƒ¼")
    print("-" * 40)
    print("1. NDJSONã‹ã‚‰ã®å„ç¨®å½¢å¼ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
    print("2. FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰")
    print("3. ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯")
    print("4. é‡è¤‡ãƒ‡ãƒ¼ã‚¿é™¤å»")
    
    choice = input("é¸æŠ: ").strip()
    
    try:
        from src.data_exporter import ProductDataExporter
        from src.faiss_rag_system import FAISSRAGSystem
        
        exporter = ProductDataExporter()
        
        if choice == "1":
            print("\nğŸ“¤ ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆä¸­...")
            
            # NDJSONã‹ã‚‰èª­ã¿è¾¼ã¿
            products = exporter.load_from_ndjson("products.ndjson")
            if not products:
                print("âŒ å‡¦ç†ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                return
            
            # å„ç¨®å½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            exporter.export_to_json(products, f"export_{timestamp}.json")
            exporter.export_to_csv(products, f"export_{timestamp}.csv") 
            exporter.export_to_sqlite(products, f"export_{timestamp}.db")
            
            print(f"âœ… {len(products)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå®Œäº†")
            
        elif choice == "2":
            print("\nğŸ”§ FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰ä¸­...")
            
            products = exporter.load_from_ndjson("products.ndjson")
            if not products:
                print("âŒ å‡¦ç†ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                return
            
            rag = FAISSRAGSystem()
            
            # å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’FAISSã«è¿½åŠ 
            products_data = []
            for product in products:
                product_dict = {
                    'id': product.id,
                    'name': product.name,
                    'description': product.description or '',
                    'category': product.category,
                    'url': product.url,
                    'tags': product.tags or [],
                    'text': f"{product.name} {product.description or ''} {' '.join(product.tags or [])}"
                }
                products_data.append(product_dict)
            
            rag.add_products(products_data)
            print(f"âœ… {len(products)} ä»¶ã®FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰å®Œäº†")
            
        elif choice == "3":
            print("\nğŸ” ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ä¸­...")
            products = exporter.load_from_ndjson("products.ndjson")
            
            if products:
                print(f"ğŸ“Š ç·å•†å“æ•°: {len(products)}")
                categories = {}
                missing_fields = {'price': 0, 'description': 0, 'image_url': 0}
                
                for product in products:
                    # ã‚«ãƒ†ã‚´ãƒªãƒ¼çµ±è¨ˆ
                    cat = product.category or 'unknown'
                    categories[cat] = categories.get(cat, 0) + 1
                    
                    # æ¬ æãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰çµ±è¨ˆ
                    if not product.price:
                        missing_fields['price'] += 1
                    if not product.description:
                        missing_fields['description'] += 1
                    if not product.image_url:
                        missing_fields['image_url'] += 1
                
                print("\nğŸ“‹ ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥å•†å“æ•°:")
                for cat, count in categories.items():
                    print(f"  {cat}: {count} ä»¶")
                
                print("\nâš ï¸ æ¬ æãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰çµ±è¨ˆ:")
                for field, count in missing_fields.items():
                    print(f"  {field}: {count} ä»¶ ({count/len(products)*100:.1f}%)")
            else:
                print("âŒ å‡¦ç†ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                
        else:
            print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™")
            
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")

def run_backup():
    """ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
    print("\nğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œä¸­...")
    
    try:
        import shutil
        import zipfile
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"backup_{timestamp}"
        backup_dir = Path("backups") / backup_name
        backup_dir.mkdir(parents=True, exist_ok=True)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ«ãƒ€ã‚’ã‚³ãƒ”ãƒ¼
        if Path("data").exists():
            shutil.copytree("data", backup_dir / "data", dirs_exist_ok=True)
        
        # ãƒ­ã‚°ã‚’ã‚³ãƒ”ãƒ¼
        if Path("logs").exists():
            shutil.copytree("logs", backup_dir / "logs", dirs_exist_ok=True)
        
        # ZIPã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä½œæˆ
        zip_path = Path("backups") / f"{backup_name}.zip"
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for file_path in backup_dir.rglob("*"):
                if file_path.is_file():
                    arcname = file_path.relative_to(backup_dir)
                    zipf.write(file_path, arcname)
        
        # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å‰Šé™¤
        shutil.rmtree(backup_dir)
        
        print(f"âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: {zip_path}")
        print(f"ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {zip_path.stat().st_size / 1024 / 1024:.2f} MB")
        logger.info(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {zip_path}")
        
    except Exception as e:
        print(f"âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

def run_data_analysis():
    """ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»çµ±è¨ˆ"""
    print("\nğŸ“ˆ ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»çµ±è¨ˆ")
    
    try:
        from src.data_exporter import ProductDataExporter
        import json
        
        exporter = ProductDataExporter()
        products = exporter.load_from_ndjson("products.ndjson")
        
        if not products:
            print("âŒ åˆ†æã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        print(f"\nğŸ“Š åŸºæœ¬çµ±è¨ˆ")
        print(f"ç·å•†å“æ•°: {len(products)}")
        print(f"ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: {products[0].source if products else 'N/A'}")
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ†æ
        categories = {}
        tag_counts = {}
        
        for product in products:
            # ã‚«ãƒ†ã‚´ãƒªãƒ¼çµ±è¨ˆ
            cat = product.category or 'ãã®ä»–'
            categories[cat] = categories.get(cat, 0) + 1
            
            # ã‚¿ã‚°çµ±è¨ˆ
            for tag in product.tags or []:
                tag_counts[tag] = tag_counts.get(tag, 0) + 1
        
        print(f"\nğŸ·ï¸ ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥å•†å“æ•°:")
        for cat, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):
            percentage = count / len(products) * 100
            print(f"  {cat}: {count} ä»¶ ({percentage:.1f}%)")
        
        print(f"\nğŸ”– äººæ°—ã‚¿ã‚° TOP5:")
        sorted_tags = sorted(tag_counts.items(), key=lambda x: x[1], reverse=True)[:5]
        for tag, count in sorted_tags:
            print(f"  {tag}: {count} ä»¶")
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        report = {
            'timestamp': datetime.now().isoformat(),
            'total_products': len(products),
            'categories': categories,
            'top_tags': dict(sorted_tags),
            'data_quality': {
                'with_price': len([p for p in products if p.price]),
                'with_description': len([p for p in products if p.description]),
                'with_image': len([p for p in products if p.image_url])
            }
        }
        
        report_file = Path("reports") / f"analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜: {report_file}")
        
    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¨ãƒ©ãƒ¼: {e}")

def show_system_settings():
    """ã‚·ã‚¹ãƒ†ãƒ è¨­å®šè¡¨ç¤º"""
    print("\nâš™ï¸ ã‚·ã‚¹ãƒ†ãƒ è¨­å®š")
    
    try:
        from config.settings import get_settings
        settings = get_settings()
        
        print("\nğŸ“‹ ç¾åœ¨ã®è¨­å®š:")
        print(f"OpenAI Model: {settings.OPENAI_MODEL}")
        print(f"Embedding Model: {settings.OPENAI_EMBEDDING_MODEL}")
        print(f"Base URL: {settings.OKUSURI_BASE_URL}")
        print(f"Request Delay: {settings.REQUEST_DELAY}ç§’")
        print(f"Max Pages: {settings.MAX_PAGES}")
        print(f"Log Level: {settings.LOG_LEVEL}")
        print(f"Streamlit Port: {settings.STREAMLIT_PORT}")
        
        # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
        print(f"\nğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª:")
        files_to_check = [
            "data/products.ndjson",
            "data/faiss_index.bin", 
            "data/metadata.pkl",
            ".env"
        ]
        
        for file_path in files_to_check:
            path = Path(file_path)
            status = "âœ…" if path.exists() else "âŒ"
            size = f"({path.stat().st_size} bytes)" if path.exists() else ""
            print(f"  {status} {file_path} {size}")
        
    except Exception as e:
        print(f"âŒ è¨­å®šç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"è¨­å®šç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")

def run_scraper():
    """å¾“æ¥ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼å®Ÿè¡Œï¼ˆäº’æ›æ€§ã®ãŸã‚æ®‹ã™ï¼‰"""
    run_data_collection()

def run_cli_recommendation():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ç‰ˆãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰å®Ÿè¡Œ"""
    print("\nğŸ” å•†å“æ¤œç´¢ãƒ»ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰ã‚·ã‚¹ãƒ†ãƒ ")
    
    try:
        from src.faiss_rag_system import FAISSRAGSystem
        
        rag = FAISSRAGSystem()
        
        print("æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã‚’åˆæœŸåŒ–ä¸­...")
        
        while True:
            print("\n" + "-"*50)
            query = input("ğŸ” æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ› (ç©ºç™½ã§æˆ»ã‚‹): ").strip()
            
            if not query:
                break
            
            print(f"\næ¤œç´¢ä¸­: '{query}'")
            results = rag.search_products(query, top_k=5)
            
            if results:
                print(f"\nğŸ“‹ æ¤œç´¢çµæœ ({len(results)} ä»¶):")
                for i, result in enumerate(results, 1):
                    print(f"\n{i}. {result.product_name}")
                    print(f"   ã‚«ãƒ†ã‚´ãƒªãƒ¼: {result.category}")
                    print(f"   é¡ä¼¼åº¦: {result.similarity_score:.3f}")
                    print(f"   èª¬æ˜: {result.description[:100]}...")
                    if result.url != "javascript:void(0)":
                        print(f"   URL: {result.url}")
            else:
                print("âŒ è©²å½“ã™ã‚‹å•†å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                
    except Exception as e:
        print(f"âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")

def run_web_ui():
    """Web UIã‚’èµ·å‹•"""
    import subprocess
    print("\nğŸŒ Streamlitã§Web UIã‚’èµ·å‹•ã—ã¾ã™...")
    print("ãƒ–ãƒ©ã‚¦ã‚¶ã§ http://localhost:8501 ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ãã ã•ã„")
    
    try:
        # Streamlitã®èµ·å‹•ç¢ºèª
        try:
            import streamlit
        except ImportError:
            print("âŒ StreamlitãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            print("   pip install streamlit ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
            return
        
        # app.pyã®å­˜åœ¨ç¢ºèª
        if not Path("app.py").exists():
            print("âŒ app.py ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        logger.info("Streamlit Web UIèµ·å‹•")
        subprocess.run([
            "streamlit", "run", "app.py", 
            "--server.port", "8501",
            "--server.address", "localhost"
        ])
    except KeyboardInterrupt:
        print("\nğŸ”š Web UIã‚’çµ‚äº†ã—ã¾ã—ãŸ")
        logger.info("Streamlit Web UIçµ‚äº†")
    except Exception as e:
        print(f"âŒ Web UIèµ·å‹•ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"Web UIèµ·å‹•ã‚¨ãƒ©ãƒ¼: {e}")

def check_system_status():
    """ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã‚’ç¢ºèª"""
    print("\nğŸ”§ ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª")
    
    try:
        from src.faiss_rag_system import FAISSRAGSystem
        from src.data_exporter import ProductDataExporter
        from config.settings import get_settings
        
        settings = get_settings()
        
        print("\n=== ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ ===")
        
        # è¨­å®šç¢ºèª
        print(f"âœ… OpenAI API Key: {'è¨­å®šæ¸ˆã¿' if settings.OPENAI_API_KEY else 'âŒ æœªè¨­å®š'}")
        print(f"âœ… OpenAI Model: {settings.OPENAI_MODEL}")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
        exporter = ProductDataExporter()
        products = exporter.load_from_ndjson("products.ndjson")
        print(f"ğŸ“Š å•†å“ãƒ‡ãƒ¼ã‚¿: {len(products) if products else 0} ä»¶")
        
        # FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç¢ºèª
        try:
            rag = FAISSRAGSystem()
            if hasattr(rag, 'index') and rag.index is not None:
                index_count = rag.index.ntotal if hasattr(rag.index, 'ntotal') else 'Unknown'
                print(f"ğŸ” FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {index_count} ä»¶")
            else:
                print("ğŸ” FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: æœªæ§‹ç¯‰")
        except Exception as e:
            print(f"ğŸ” FAISSã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: ã‚¨ãƒ©ãƒ¼ ({e})")
        
        # ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡
        data_dir = Path("data")
        if data_dir.exists():
            total_size = sum(f.stat().st_size for f in data_dir.rglob('*') if f.is_file())
            print(f"ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡: {total_size / 1024 / 1024:.2f} MB")
        
        # æœ€æ–°ã®ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒª
        log_file = Path("logs/app.log")
        if log_file.exists():
            log_size = log_file.stat().st_size / 1024
            print(f"ğŸ“ ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: {log_size:.2f} KB")
        
        print("\n=== å‹•ä½œãƒ†ã‚¹ãƒˆ ===")
        
        # ç°¡å˜ãªæ¤œç´¢ãƒ†ã‚¹ãƒˆ
        if products:
            try:
                rag = FAISSRAGSystem()
                test_results = rag.search_products("æ²»ç™‚", top_k=1)
                if test_results:
                    print(f"âœ… æ¤œç´¢æ©Ÿèƒ½: æ­£å¸¸å‹•ä½œ (ãƒ†ã‚¹ãƒˆçµæœ: {test_results[0].product_name})")
                else:
                    print("âš ï¸ æ¤œç´¢æ©Ÿèƒ½: çµæœãªã—")
            except Exception as e:
                print(f"âŒ æ¤œç´¢æ©Ÿèƒ½: ã‚¨ãƒ©ãƒ¼ ({e})")
        else:
            print("âš ï¸ æ¤œç´¢æ©Ÿèƒ½: ãƒ‡ãƒ¼ã‚¿ãªã—")
        
        print("\n=== æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ ===")
        if not products:
            print("1. ã¾ãšã€Œå•†å“ãƒ‡ãƒ¼ã‚¿åé›†ã€ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        if not settings.OPENAI_API_KEY:
            print("2. .envãƒ•ã‚¡ã‚¤ãƒ«ã«OPENAI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„")
        if products and len(products) < 10:
            print("3. ã‚ˆã‚Šå¤šãã®å•†å“ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™")
        
    except Exception as e:
        print(f"âŒ ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    main()

def run_scraper():
    """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚’å®Ÿè¡Œ"""
    from src.scraper import main as scraper_main
    print("\nğŸ•·ï¸ å•†å“ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’é–‹å§‹...")
    scraper_main()

def run_cli_recommendation():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ç‰ˆãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰å®Ÿè¡Œ"""
    from src.recommendation_engine import main as recommendation_main
    print("\nğŸ” ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ç‰ˆãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰å®Ÿè¡Œ...")
    recommendation_main()

def run_web_ui():
    """Web UIã‚’èµ·å‹•"""
    import subprocess
    print("\nğŸŒ Streamlitã§Web UIã‚’èµ·å‹•ã—ã¾ã™...")
    print("ãƒ–ãƒ©ã‚¦ã‚¶ã§ http://localhost:8501 ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ãã ã•ã„")
    
    try:
        subprocess.run([
            "streamlit", "run", "app.py", 
            "--server.port", "8501",
            "--server.address", "localhost"
        ])
    except KeyboardInterrupt:
        print("\nWeb UIã‚’çµ‚äº†ã—ã¾ã—ãŸ")
    except Exception as e:
        print(f"Web UIèµ·å‹•ã‚¨ãƒ©ãƒ¼: {e}")

def check_system_status():
    """ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã‚’ç¢ºèª"""
    try:
        from src.recommendation_engine import RecommendationEngine
        
        print("\nğŸ”§ ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ã‚’ç¢ºèªä¸­...")
        engine = RecommendationEngine()
        status = engine.get_system_status()
        
        print("\n=== ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ ===")
        for key, value in status.items():
            print(f"{key}: {value}")
            
    except Exception as e:
        print(f"ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    main()